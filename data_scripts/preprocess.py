# preprocess.py
"""
æ­¤è…³æœ¬è² è²¬ï¼š
1. è¼‰å…¥è¨“ç·´èˆ‡æ¸¬è©¦ JSON æª”æ¡ˆã€‚
2. å°åˆ†é¡æ¬„ä½ï¼ˆCategory, Concept, Subcategoryï¼‰é€²è¡Œ One-hot ç·¨ç¢¼ã€‚
3. ä½¿ç”¨ BERTopic å° Alltags æ¬„ä½åšä¸»é¡Œå»ºæ¨¡ä¸¦åŠ å…¥ topic å‘é‡ã€‚
4. åˆä½µè¨“ç·´è³‡æ–™èˆ‡å°æ‡‰æ¨™ç±¤ã€‚
5. å°‡è™•ç†å¾Œè³‡æ–™å„²å­˜æˆ CSVï¼Œä¸¦å„²å­˜ OneHotEncoder ç‰©ä»¶ä»¥ä¾¿æ—¥å¾Œä½¿ç”¨ã€‚
"""

import pandas as pd
import json
from sklearn.preprocessing import OneHotEncoder
import pickle
import os
from bertopic import BERTopic
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# è¼‰å…¥è¨“ç·´èˆ‡æ¸¬è©¦ JSONï¼ˆæ ¼å¼ç‚º JSON é™£åˆ—ï¼‰
with open('./data/train_data.json') as f:
    train_data = json.load(f)

with open('./data/test_data.json') as f:
    test_data = json.load(f)

train_df = pd.DataFrame(train_data)
test_df = pd.DataFrame(test_data)

# ç´€éŒ„è¨“ç·´è³‡æ–™é•·åº¦
train_len = len(train_df)

# ç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨
cat_cols = ['Category', 'Concept', 'Subcategory']
for col in cat_cols:
    if col not in train_df.columns:
        train_df[col] = ""
    if col not in test_df.columns:
        test_df[col] = ""

# åˆä½µä»¥ä¾¿é€²è¡Œ encoder.fit
all_df = pd.concat([train_df, test_df], axis=0)

# One-hot encode é¡åˆ¥æ¬„
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoded = encoder.fit_transform(all_df[cat_cols])
encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(cat_cols))

# === ä½¿ç”¨ BERTopic å° Alltags åšä¸»é¡Œå»ºæ¨¡ ===
print("ğŸš€ å»ºç«‹ BERTopic æ¨¡å‹...")
docs = all_df['Alltags'].astype(str).fillna("None").tolist()
topic_model = BERTopic(language="multilingual", calculate_probabilities=True)
topics, probs = topic_model.fit_transform(docs)

topic_df = pd.DataFrame(probs, columns=[f"Topic_{i}" for i in range(probs.shape[1])])
print(f"âœ… BERTopic ä¸»é¡Œç¶­åº¦ï¼š{topic_df.shape[1]}")

# åˆä½µç·¨ç¢¼èˆ‡ä¸»é¡Œçµæœ
all_df = pd.concat([all_df.reset_index(drop=True), encoded_df, topic_df], axis=1).drop(columns=cat_cols)
print(f"âœ… all-dfç¶­åº¦ï¼ˆå« topicï¼‰ï¼š{all_df.shape}")

# åˆ‡å› train / test
train_df = all_df.iloc[:train_len].copy()
test_df = all_df.iloc[train_len:].copy()

# åˆä½µ label
label_df = pd.read_csv('./data/train_label.csv')
train_df = train_df.merge(label_df, on='Pid', how='left')

# å„²å­˜ CSV
train_df.to_csv('./data/train.csv', index=False)
test_df.to_csv('./data/test.csv', index=False)

# å„²å­˜ encoder
os.makedirs('./experiments/checkpoints', exist_ok=True)
with open('./experiments/checkpoints/encoder.pkl', 'wb') as f:
    pickle.dump(encoder, f)

# å„²å­˜ topic modelï¼ˆå¯é¸ï¼‰
topic_model.save("./experiments/checkpoints/bertopic_model")
