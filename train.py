# # train.py
# """
# è¨“ç·´è…³æœ¬ï¼š
# è¼‰å…¥å¤šæ¨¡æ…‹è³‡æ–™é›†ã€æ¨¡å‹èˆ‡æå¤±å‡½æ•¸ï¼Œé€²è¡Œè¿´åœˆå¼è¨“ç·´èˆ‡æ¨¡å‹å„²å­˜ã€‚
# """

# import torch
# import torch.nn as nn
# from torch.utils.data import DataLoader
# from transformers import BertTokenizer
# from tqdm import tqdm
# import os

# from data_scripts.dataset import MultimodalDataset
# from data_scripts.transform import image_transforms
# from models.multimodal_net import MultimodalNet

# # è£ç½®è¨­å®š
# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# # åƒæ•¸
# BATCH_SIZE = 16
# EPOCHS = 10
# LR = 1e-4

# # Tokenizer è¼‰å…¥
# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# # è¼‰å…¥è¨“ç·´è³‡æ–™
# train_dataset = MultimodalDataset(
#     csv_path='data/train.csv',
#     tokenizer=tokenizer,
#     image_root='data',
#     transform=image_transforms
# )
# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

# # æ±ºå®šç¤¾æœƒç‰¹å¾µç¶­åº¦ï¼ˆå‡è¨­ç¬¬ä¸€ç­†å°±å…·ä»£è¡¨æ€§ï¼‰
# social_dim = train_dataset[0]['social'].shape[0]

# # æ¨¡å‹å»ºç«‹
# model = MultimodalNet(feature_dims=[768, 768, social_dim]).to(DEVICE)

# # æå¤±èˆ‡å„ªåŒ–å™¨
# criterion = nn.L1Loss()  # ä½¿ç”¨ MAE ä½œç‚ºå›æ­¸æå¤±
# optimizer = torch.optim.Adam(model.parameters(), lr=LR)

# # å„²å­˜è·¯å¾‘
# os.makedirs('./experiments/checkpoints', exist_ok=True)
# best_loss = float('inf')

# # è¨“ç·´è¿´åœˆ
# for epoch in range(EPOCHS):
#     model.train()
#     total_loss = 0
#     pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")

#     for batch in pbar:
#         input_ids = batch['title_input_ids'].to(DEVICE)
#         attention_mask = batch['title_mask'].to(DEVICE)
#         images = batch['image'].to(DEVICE)
#         social = batch['social'].to(DEVICE)
#         labels = batch['label'].to(DEVICE)

#         optimizer.zero_grad()
#         outputs = model((input_ids, attention_mask), images, social)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         total_loss += loss.item()
#         pbar.set_postfix(loss=loss.item())

#     avg_loss = total_loss / len(train_loader)
#     print(f"\nEpoch {epoch+1} Average Loss: {avg_loss:.4f}")

#     # å„²å­˜æœ€ä½³æ¨¡å‹
#     if avg_loss < best_loss:
#         best_loss = avg_loss
#         torch.save(model.state_dict(), './experiments/checkpoints/best_model.pt')
#         print("âœ… Saved new best model.")



# train.py
"""
ä¸Šé¢æ˜¯èˆŠçš„è¨“ç·´è…³æœ¬ï¼Œä¸‹é¢æ˜¯æ–°çš„è¨“ç·´è…³æœ¬
------
è¨“ç·´è…³æœ¬ï¼š
è¼‰å…¥å¤šæ¨¡æ…‹è³‡æ–™é›†ã€æ¨¡å‹èˆ‡æå¤±å‡½æ•¸ï¼Œé€²è¡Œè¨“ç·´èˆ‡é©—è­‰ï¼Œ
ä½¿ç”¨ validation loss æ±ºå®šæœ€ä½³æ¨¡å‹ä¸¦å„²å­˜ï¼Œä¸¦ç¹ªè£½ loss æ›²ç·šï¼ˆå«æ™‚é–“æˆ³è¨˜ç‰ˆæ§ï¼‰ã€‚
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from transformers import BertTokenizer
from tqdm import tqdm
import matplotlib.pyplot as plt
import os
from datetime import datetime

from data_scripts.dataset import MultimodalDataset
from data_scripts.transform import image_transforms
from models.multimodal_net import MultimodalNet

# è£ç½®è¨­å®š
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# åƒæ•¸
BATCH_SIZE = 16
EPOCHS = 30
LR = 1e-4
VAL_RATIO = 0.1
EARLY_STOPPING_PATIENCE = 5

# æ™‚é–“æˆ³è¨˜
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
save_dir = f'./experiments/checkpoints/{timestamp}'
os.makedirs(save_dir, exist_ok=True)

# Tokenizer è¼‰å…¥
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# è¼‰å…¥ä¸¦åˆ‡åˆ†è¨“ç·´è³‡æ–™
dataset = MultimodalDataset(
    csv_path='data/train.csv',
    tokenizer=tokenizer,
    image_root='data',
    transform=image_transforms
)
val_size = int(len(dataset) * VAL_RATIO)
train_size = len(dataset) - val_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# æ¨¡å‹å»ºç«‹
social_dim = dataset[0]['social'].shape[0]
model = MultimodalNet(feature_dims=[768, 768, 768, social_dim]).to(DEVICE)

# æå¤±èˆ‡å„ªåŒ–å™¨
criterion = nn.L1Loss()
optimizer = torch.optim.Adam(model.parameters(), lr=LR)

# early stopping è®Šæ•¸
best_val_loss = float('inf')
all_train_losses = []
all_val_losses = []
patience_counter = 0

# è¨“ç·´è¿´åœˆ
for epoch in range(EPOCHS):
    model.train()
    train_loss = 0
    pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")

    for batch in pbar:
        title_ids = batch['title_input_ids'].to(DEVICE)
        title_mask = batch['title_mask'].to(DEVICE)
        tag_ids = batch['tag_input_ids'].to(DEVICE)
        tag_mask = batch['tag_mask'].to(DEVICE)
        images = batch['image'].to(DEVICE)
        social = batch['social'].to(DEVICE)
        labels = batch['label'].to(DEVICE)

        optimizer.zero_grad()
        outputs = model((title_ids, title_mask), (tag_ids, tag_mask), images, social)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        pbar.set_postfix(loss=loss.item())

    avg_train_loss = train_loss / len(train_loader)
    all_train_losses.append(avg_train_loss)

    # é©—è­‰éšæ®µ
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for batch in val_loader:
            title_ids = batch['title_input_ids'].to(DEVICE)
            title_mask = batch['title_mask'].to(DEVICE)
            tag_ids = batch['tag_input_ids'].to(DEVICE)
            tag_mask = batch['tag_mask'].to(DEVICE)
            images = batch['image'].to(DEVICE)
            social = batch['social'].to(DEVICE)
            labels = batch['label'].to(DEVICE)

            outputs = model((title_ids, title_mask), (tag_ids, tag_mask), images, social)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

    avg_val_loss = val_loss / len(val_loader)
    all_val_losses.append(avg_val_loss)
    print(f"\nEpoch {epoch+1} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")

    # å„²å­˜æœ€ä½³æ¨¡å‹
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        model_path = os.path.join(save_dir, 'best_model.pt')
        torch.save(model.state_dict(), model_path)
        print(f"âœ… Saved new best model to {model_path}")
        patience_counter = 0
    else:
        patience_counter += 1
        if patience_counter >= EARLY_STOPPING_PATIENCE:
            print(f"â¹ Early stopping triggered after {epoch+1} epochs.")
            break

# ç¹ªè£½ loss æ›²ç·š
plt.figure()
plt.plot(range(1, len(all_train_losses)+1), all_train_losses, label='Train Loss')
plt.plot(range(1, len(all_val_losses)+1), all_val_losses, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('MAE Loss')
plt.title('Training & Validation Loss Curve')
plt.legend()
plt.grid(True)
fig_path = os.path.join(save_dir, 'loss_curve.png')
plt.savefig(fig_path)
print(f"ğŸ“ˆ Loss curve saved to {fig_path}")
