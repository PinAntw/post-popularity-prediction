# build_hashtag_graph.py (with NeighborLoader)
"""
æ­¤è…³æœ¬è² è²¬ï¼š
1. å¾ train_data.json / test_data.json å»ºç«‹ hashtag å…±ç¾åœ–
2. ä½¿ç”¨ GraphSAGE + NeighborLoader é€²è¡Œ mini-batch è¨“ç·´
3. å„²å­˜æ¯å€‹ hashtag ç¯€é»çš„å‘é‡åˆ° graph_emb_dict.pkl
"""

import json
import pandas as pd
import networkx as nx
from itertools import combinations
from sklearn.preprocessing import LabelEncoder
import torch
from torch_geometric.data import Data
from torch_geometric.nn import SAGEConv
from torch_geometric.loader import NeighborLoader
import torch.nn.functional as F
import pickle
import os

# åƒæ•¸
json_paths = ['./data/train_data.json', './data/test_data.json']
emb_dim = 64
output_path = './experiments/checkpoints/graph_emb_dict.pkl'

# 1. è¼‰å…¥è³‡æ–™ä¸¦æŠ½å‡º hashtag åˆ—è¡¨
print("ğŸ“¥ è¼‰å…¥è³‡æ–™...")
all_hashtag_lists = []
for path in json_paths:
    with open(path) as f:
        records = json.load(f)
        for r in records:
            hashtags = r.get('Alltags', '')
            if hashtags:
                tag_list = hashtags.strip().split()
                all_hashtag_lists.append(tag_list)

# 2. å»ºç«‹ hashtag å…±ç¾åœ–
print("ğŸ”— å»ºç«‹å…±ç¾åœ–...")
print(f"  - ç¸½ hashtag æ•¸é‡: {len(all_hashtag_lists)}")
G = nx.Graph()
for tags in all_hashtag_lists:
    for a, b in combinations(set(tags), 2):
        if G.has_edge(a, b):
            G[a][b]['weight'] += 1
        else:
            G.add_edge(a, b, weight=1)

nodes = list(G.nodes)
le = LabelEncoder()
le.fit(nodes)
id2tag = {i: tag for i, tag in enumerate(le.classes_)}

src = []
dst = []
for u, v in G.edges():
    src.append(le.transform([u])[0])
    dst.append(le.transform([v])[0])

edge_index = torch.tensor([src, dst], dtype=torch.long)
x = torch.eye(len(nodes))
data = Data(x=x, edge_index=edge_index)
data.num_nodes = x.size(0)  # âœ… VERY IMPORTANT

# 3. å®šç¾© GraphSAGE æ¨¡å‹
class GNN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = SAGEConv(in_channels, hidden_channels)
        self.conv2 = SAGEConv(hidden_channels, out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return x

# 4. ä½¿ç”¨ NeighborLoader è¨“ç·´
print("ğŸ§  Mini-batch è¨“ç·´ GraphSAGE...")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GNN(x.size(1), 128, emb_dim).to(device)
data = data.to(device)

train_loader = NeighborLoader(
    data,
    num_neighbors=[10, 10],
    batch_size=512,
    shuffle=True
)

optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
model.train()
for epoch in range(20):
    total_loss = 0
    for batch in train_loader:
        batch = batch.to(device)
        optimizer.zero_grad()
        out = model(batch.x, batch.edge_index)
        loss = (out @ out.T).mean()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch:02d}, Loss: {total_loss:.4f}")

# 5. å…¨åœ–æ¨è«–ï¼ˆç”¢ç”Ÿå®Œæ•´ç¯€é»åµŒå…¥ï¼‰
print("ğŸ“¤ æ¨è«–åµŒå…¥ä¸¦å„²å­˜...")
model.eval()
with torch.no_grad():
    final_emb = model(data.x.to(device), data.edge_index.to(device)).cpu()

graph_emb_dict = {id2tag[i]: final_emb[i].numpy() for i in range(len(id2tag))}
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, 'wb') as f:
    pickle.dump(graph_emb_dict, f)

print(f"âœ… Graph embeddings saved to {output_path}")