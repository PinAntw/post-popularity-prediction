# build_hashtag_graph.py (full-graph version with caching and data save)
"""
æ­¤è…³æœ¬è² è²¬ï¼š
1. å¾ train_data.json / test_data.json å»ºç«‹ hashtag å…±ç¾åœ–ï¼ˆåŠ é€Ÿç‰ˆï¼‰
2. ä½¿ç”¨ GraphSAGE åœ¨æ•´åœ–ä¸Šè¨“ç·´
3. å„²å­˜æ¯å€‹ hashtag ç¯€é»çš„å‘é‡åˆ° graph_emb_dict.pkl
4. åœ–ç‰©ä»¶ data ä¹Ÿå¿«å–å„²å­˜ï¼ŒåŠ é€Ÿå¾ŒçºŒä½¿ç”¨
"""

import json
import networkx as nx
from collections import defaultdict, Counter
from sklearn.preprocessing import LabelEncoder
import torch
from torch_geometric.data import Data
from torch_geometric.nn import SAGEConv
import torch.nn.functional as F
import pickle
import os

# åƒæ•¸
json_paths = ['./data/train_data.json', './data/test_data.json']
emb_dim = 64
output_path = './experiments/checkpoints/graph_emb_dict.pkl'
cache_path = './experiments/checkpoints/graph_cache.pkl'
data_cache_path = './experiments/checkpoints/graph_data.pkl'

# ====== å…±ç¾åœ–å»ºç«‹æˆ–è¼‰å…¥ ======
if os.path.exists(cache_path):
    print("â™»ï¸ åµæ¸¬åˆ°å¿«å–ï¼Œè¼‰å…¥å…±ç¾åœ–...")
    with open(cache_path, 'rb') as f:
        G, le, id2tag = pickle.load(f)
else:
    print("ğŸ“¥ è¼‰å…¥è³‡æ–™ä¸¦å»ºç«‹å…±ç¾åœ–...")
    all_hashtag_lists = []
    for path in json_paths:
        with open(path) as f:
            records = json.load(f)
            for r in records:
                hashtags = r.get('Alltags', '')
                if hashtags:
                    tag_list = hashtags.strip().split()
                    all_hashtag_lists.append(tag_list)

    print("ğŸ”— å»ºç«‹å…±ç¾åœ–ï¼ˆåŠ é€Ÿç‰ˆï¼‰...")
    print(f"  - ç¸½ hashtag ç­†æ•¸: {len(all_hashtag_lists)}")
    edge_counter = defaultdict(Counter)
    for tags in all_hashtag_lists:
        uniq_tags = list(set(tags))
        for i in range(len(uniq_tags)):
            for j in range(i + 1, len(uniq_tags)):
                a, b = sorted([uniq_tags[i], uniq_tags[j]])
                edge_counter[a][b] += 1

    edges = []
    for a, neighbors in edge_counter.items():
        for b, weight in neighbors.items():
            edges.append((a, b, weight))

    print(f"  - å…±è¨ˆé‚Šæ•¸ï¼š{len(edges)}")
    G = nx.Graph()
    G.add_weighted_edges_from(edges)

    nodes = list(G.nodes)
    le = LabelEncoder()
    le.fit(nodes)
    id2tag = {i: tag for i, tag in enumerate(le.classes_)}

    os.makedirs(os.path.dirname(cache_path), exist_ok=True)
    with open(cache_path, 'wb') as f:
        pickle.dump((G, le, id2tag), f)
    print("âœ… å…±ç¾åœ–å·²å¿«å–å„²å­˜")

# ====== å»ºç«‹åœ–è³‡æ–™ç‰©ä»¶æˆ–å¿«å–è¼‰å…¥ ======
if os.path.exists(data_cache_path):
    print("ğŸ“¦ è¼‰å…¥å¿«å–çš„åœ–è³‡æ–™ç‰©ä»¶ data...")
    with open(data_cache_path, 'rb') as f:
        data = pickle.load(f)
else:
    print("ğŸ§± å»ºç«‹åœ–è³‡æ–™ç‰©ä»¶...")
    tag2id = {tag: idx for idx, tag in enumerate(le.classes_)}
    src = []
    dst = []
    for u, v in G.edges():
        src.append(tag2id[u])
        dst.append(tag2id[v])

    edge_index = torch.tensor([src, dst], dtype=torch.long)
    # x = torch.eye(len(G.nodes))
    x = torch.randn(len(G.nodes), 64)  # éš¨æ©Ÿåˆå§‹åŒ–ç¯€é»ç‰¹å¾µï¼ˆé¿å… one-hot çˆ†é¡¯å­˜ï¼‰
    data = Data(x=x, edge_index=edge_index)
    data.num_nodes = x.size(0)

    with open(data_cache_path, 'wb') as f:
        pickle.dump(data, f)
    print("âœ… åœ–è³‡æ–™ç‰©ä»¶å·²å„²å­˜è‡³å¿«å–")

# ====== å®šç¾© GraphSAGE æ¨¡å‹ ======
class GNN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = SAGEConv(in_channels, hidden_channels)
        self.conv2 = SAGEConv(hidden_channels, out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return x

# ====== å…¨åœ–è¨“ç·´ ======
print("ğŸ§  Full-graph è¨“ç·´ GraphSAGE...")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GNN(data.x.size(1), 128, emb_dim).to(device)
data = data.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

model.train()
for epoch in range(20):
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = out.norm(p=2, dim=1).mean()
    loss.backward()
    optimizer.step()
    print(f"Epoch {epoch:02d}, Loss: {loss.item():.4f}")

# ====== æ¨è«–åµŒå…¥ä¸¦å„²å­˜ ======
print("ğŸ“¤ æ¨è«–åµŒå…¥ä¸¦å„²å­˜...")
model.eval()
with torch.no_grad():
    final_emb = model(data.x.to(device), data.edge_index.to(device)).cpu()

graph_emb_dict = {id2tag[i]: final_emb[i].numpy() for i in range(len(id2tag))}
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, 'wb') as f:
    pickle.dump(graph_emb_dict, f)

print(f"âœ… Graph embeddings saved to {output_path}")
